# -*- coding: utf-8 -*-
"""inception_Cifar10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ArXjovRFGqEqjSPqFwr2SojRIoMiokU9
"""

import tensorflow as tf

from tensorflow.keras.layers import Reshape, Dropout, Dense,Multiply, Dot, Concatenate,Embedding

tf.__version__

"""# New Section"""

from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input
import tensorflow.keras as keras
from tensorflow.keras import models
from tensorflow.keras import layers
from tensorflow.keras import optimizers
import tensorflow as tf
from keras.utils import np_utils
from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import cv2
from keras.applications.vgg16 import VGG16, preprocess_input
from keras.datasets import cifar10

conv_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(200, 200, 3))

conv_base.summary()

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

x_train = x_train / 255.0
x_test = x_test / 255.0

y_train = np_utils.to_categorical(y_train, 10)
y_test = np_utils.to_categorical(y_test, 10)

print(x_train.shape)
print(x_test.shape)

model = models.Sequential()
model.add(layers.UpSampling2D((2,2)))
model.add(layers.UpSampling2D((2,2)))
model.add(layers.UpSampling2D((2,2)))
model.add(conv_base)
model.add(layers.Flatten(input_shape=(256,256,3)))
model.add(layers.Dense(128, activation='tanh'))
model.add(layers.Dropout(0.5))
model.add(layers.BatchNormalization())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.BatchNormalization())
model.add(layers.Dense(10, activation='softmax'))
model.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['acc'])

history = model.fit(x_train, y_train, steps_per_epoch=100, epochs=20, batch_size=30, validation_data=(x_test, y_test))

#model = tf.keras.models.load_model('my_model.h5')
model.save ("/content/drive/My Drive/Resume/cifar_model.h5")

model1 = tf.keras.models.load_model("/content/drive/My Drive/Resume/cifar_model.h5")

model1

from matplotlib.pyplot import imshow
import cv2
from google.colab.patches import cv2_imshow
from skimage import io

input_img= "http://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane1.png"

input_img = io.imread(input_img)
input_img = cv2.resize(input_img, dsize=(50, 50), interpolation=cv2.INTER_CUBIC)
print('Input Dimensions - Image : ',input_img.shape)
cv2_imshow(input_img)

import numpy as np
from keras.preprocessing import image
input_img = cv2.resize(input_img, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)
x = image.img_to_array(input_img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = model1.predict(x)
class_idx = np.argmax(preds[0])
preds[0],class_idx

preds

class_idx

for layer in conv_base.layers:
  layer.trainable = False

from google.colab import drive
drive.mount('/content/gdrive')

root_path='/content/drive/My Drive/iNeuron/pics'

!unzip 'datasets_grey.zip'

!ls

# useful for getting number of classes
from glob import glob
folders = glob('/content/drive/My Drive/iNeuron/pics/*')
print(len(folders))

from keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

test_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

train_set = train_datagen.flow_from_directory('12_superheros/CAX_Superhero_Train',
                                                 target_size = (150,150),
                                                 batch_size = 32,
                                                 class_mode = 'binary')

test_set = test_datagen.flow_from_directory('/content/drive/My Drive/iNeuron/pics/test/',
                                           target_size = (75,75),
                                           batch_size = 32,
                                           ass_mode = 'categorical')

model = models.Sequential()
model.add(layers.UpSampling2D((2,2)))
model.add(layers.UpSampling2D((2,2)))
model.add(layers.UpSampling2D((2,2)))
model.add(conv_base)
model.add(layers.Flatten())
#model.add(layers.k())
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.BatchNormalization())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.BatchNormalization())
model.add(layers.Dense(1, activation='sigmoid'))

model.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['acc'])

model.fit_generator(x_train,y_train epochs=1, verbose=1,steps_per_epoch=5, validation_data=(x_train,y_test))

import PIL
PIL.__version__

from keras.utils import plot_model
# plot model architecture
plot_model(conv_base, show_shapes=True, to_file='multiple_vgg_blocks.png')





from keras.utils import plot_model
# plot model architecture
plot_model(model, show_shapes=True, to_file='multiple_vgg_blocks.png')





"""# New Section"""



